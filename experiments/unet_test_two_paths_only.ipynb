{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is enabled with initial size: 85.0% of memory, CuDNN 3007)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  _____                _____                 _\n",
      " |  _  \\              |  __ \\               | |\n",
      " | | | |___  ___ _ __ | |  \\/_ __ __ _ _ __ | |__\n",
      " | | | / _ \\/ _ \\ '_ \\| | __| '__/ _` | '_ \\| '_ \\\n",
      " | |/ /  __/  __/ |_) | |_\\ \\ | | (_| | |_) | | | |\n",
      " |___/ \\___|\\___| .__/ \\____/_|  \\__,_| .__/|_| |_|\n",
      "                | |                   | |\n",
      "                |_|                   |_|\n",
      "\n",
      "\n",
      "Available on GitHub: https://github.com/sebastian-schlecht/deepgraph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from deepgraph.utils.logging import log\n",
    "from deepgraph.utils.common import batch_parallel, ConfigMixin, shuffle_in_unison_inplace, pickle_dump\n",
    "from deepgraph.utils.image import batch_pad_mirror, rotate_transformer_scalar_float32, rotate_transformer_rgb_uint8\n",
    "from deepgraph.constants import *\n",
    "from deepgraph.conf import rng\n",
    "from deepgraph.nn.core import Dropout\n",
    "\n",
    "from deepgraph.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "class Transformer(Processor):\n",
    "    \"\"\"\n",
    "    Apply online random augmentation.\n",
    "    \"\"\"\n",
    "    def __init__(self, name, shapes, config, buffer_size=10):\n",
    "        super(Transformer, self).__init__(name, shapes, config, buffer_size)\n",
    "        self.mean = None\n",
    "\n",
    "    def init(self):\n",
    "        if self.conf(\"mean_file\") is not None:\n",
    "            self.mean = np.load(self.conf(\"mean_file\"))\n",
    "        else:\n",
    "            log(\"Transformer - No mean file specified.\", LOG_LEVEL_WARNING)\n",
    "\n",
    "    def process(self):\n",
    "        packet = self.pull()\n",
    "        # Return if no data is there\n",
    "        if not packet:\n",
    "            return False\n",
    "        # Unpack\n",
    "        data, label = packet.data\n",
    "        # Do processing\n",
    "        log(\"Transformer - Processing data\", LOG_LEVEL_VERBOSE)\n",
    "        i_h = 228\n",
    "        i_w = 304\n",
    "\n",
    "        d_h = 228\n",
    "        d_w = 304\n",
    "\n",
    "        start = time.time()\n",
    "        # Mean\n",
    "        if packet.phase == PHASE_TRAIN or packet.phase == PHASE_VAL:\n",
    "            data = data.astype(np.float32)\n",
    "            if self.mean is not None:\n",
    "                for idx in range(data.shape[0]):\n",
    "                    # Subtract mean\n",
    "                    data[idx] = data[idx] - self.mean.astype(np.float32)\n",
    "            if self.conf(\"offset\") is not None:\n",
    "                label -= self.conf(\"offset\")\n",
    "\n",
    "        if packet.phase == PHASE_TRAIN:\n",
    "            # Do elementwise operations\n",
    "\n",
    "            data_old = data\n",
    "            label_old = label\n",
    "            data = np.zeros((data_old.shape[0], data_old.shape[1], i_h, i_w), dtype=np.float32)\n",
    "            label = np.zeros((label_old.shape[0], d_h, d_w), dtype=np.float32)\n",
    "            for idx in range(data.shape[0]):\n",
    "                # Rotate\n",
    "                # We rotate before cropping to be able to get filled corners\n",
    "                # Maybe even adjust the border after rotating\n",
    "                deg = np.random.randint(-5,6)\n",
    "                # Operate on old data. Careful - data is already in float so we need to normalize and rescale afterwards\n",
    "                # data_old[idx] = 255. * rotate_transformer_rgb_uint8(data_old[idx] * 0.003921568627, deg).astype(np.float32)\n",
    "                # label_old[idx] = rotate_transformer_scalar_float32(label_old[idx], deg)\n",
    "                \n",
    "                # Take care of any empty areas, we crop on a smaller surface depending on the angle\n",
    "                # TODO Remove this once loss supports masking\n",
    "                shift = 0 #np.tan((deg/180.) * math.pi)\n",
    "                # Random crops\n",
    "                cy = rng.randint(data_old.shape[2] - d_h - shift, size=1)\n",
    "                cx = rng.randint(data_old.shape[3] - d_w - shift, size=1)\n",
    "\n",
    "                data[idx] = data_old[idx, :, cy:cy+i_h, cx:cx+i_w]\n",
    "                label[idx] = label_old[idx, cy:cy+d_h, cx:cx+d_w]\n",
    "\n",
    "                # Flip horizontally with probability 0.5\n",
    "                p = rng.randint(2)\n",
    "                if p > 0:\n",
    "                    data[idx] = data[idx, :, :, ::-1]\n",
    "                    label[idx] = label[idx, :, ::-1]\n",
    "\n",
    "                # RGB we mult with a random value between 0.8 and 1.2\n",
    "                r = rng.randint(80,121) / 100.\n",
    "                g = rng.randint(80,121) / 100.\n",
    "                b = rng.randint(80,121) / 100.\n",
    "                data[idx, 0] = data[idx, 0] * r\n",
    "                data[idx, 1] = data[idx, 1] * g\n",
    "                data[idx, 2] = data[idx, 2] * b\n",
    "\n",
    "            # Shuffle\n",
    "            # data, label = shuffle_in_unison_inplace(data, label)\n",
    "        elif packet.phase == PHASE_VAL:\n",
    "            # Center crop\n",
    "            cy = (data.shape[2] - i_h) // 2\n",
    "            cx = (data.shape[3] - i_w) // 2\n",
    "            data = data[:, :, cy:cy+i_h, cx:cx+i_w]\n",
    "            label = label[:, cy:cy+d_h, cx:cx+d_w]\n",
    "        end = time.time()\n",
    "        log(\"Transformer - Processing took \" + str(end - start) + \" seconds.\", LOG_LEVEL_VERBOSE)\n",
    "        # Try to push into queue as long as thread should not terminate\n",
    "        self.push(Packet(identifier=packet.id, phase=packet.phase, num=2, data=(data, label)))\n",
    "        return True\n",
    "\n",
    "    def setup_defaults(self):\n",
    "        super(Transformer, self).setup_defaults()\n",
    "        self.conf_default(\"mean_file\", None)\n",
    "        self.conf_default(\"offset\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano.tensor.nnet import relu\n",
    "\n",
    "from deepgraph.graph import *\n",
    "from deepgraph.nn.core import *\n",
    "from deepgraph.nn.conv import *\n",
    "from deepgraph.nn.loss import *\n",
    "from deepgraph.solver import *\n",
    "from deepgraph.nn.init import *\n",
    "\n",
    "from deepgraph.pipeline import Optimizer, H5DBLoader, Pipeline\n",
    "\n",
    "\n",
    "def build_graph():\n",
    "    graph = Graph(\"unet\")\n",
    "\n",
    "    data            = Data(graph, \"data\", T.ftensor4, shape=(-1, 3, 228, 304))\n",
    "    label           = Data(graph, \"label\", T.ftensor3, shape=(-1, 1, 228, 304), config={\n",
    "        \"phase\": PHASE_TRAIN\n",
    "    })\n",
    "    \n",
    "    conv_c1_1     = Conv2D(graph, \"conv_c1_1\", config={\n",
    "            \"channels\": 64,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    conv_c1_2     = Conv2D(graph, \"conv_c1_2\", config={\n",
    "            \"channels\": 64,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    pool_c1 = Pool(graph, \"pool_c0\", config={\n",
    "        \"kernel\": (2, 2)\n",
    "    })\n",
    "    \n",
    "    conv_c2_1     = Conv2D(graph, \"conv_c2_1\", config={\n",
    "            \"channels\": 128,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    conv_c2_2     = Conv2D(graph, \"conv_c2_2\", config={\n",
    "            \"channels\": 128,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    \n",
    "    up_e2 = Upsample(graph, \"up_e2\", config={\n",
    "            \"kernel\": (2, 2)\n",
    "    })\n",
    "    up_conv_e2 = Conv2D(graph, \"up_conv_e2\", config={\n",
    "            \"channels\": 64,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": None,\n",
    "            \"weight_filler\": xavier(),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    concat_1 = Concatenate(graph, \"concat_1\", config={\n",
    "            \"axis\": 1\n",
    "    })\n",
    "    \n",
    "    conv_e1_1 = Conv2D(graph, \"conv_e1_1\", config={\n",
    "            \"channels\": 64,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    conv_e1_2 = Conv2D(graph, \"conv_e1_2\", config={\n",
    "            \"channels\": 64,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    conv_e_f= Conv2D(graph, \"conv_e_f\", config={\n",
    "            \"channels\": 1,\n",
    "            \"kernel\": (1, 1),\n",
    "            \"activation\": None,\n",
    "            \"weight_filler\": xavier(),\n",
    "            \"bias_filler\": constant(0)\n",
    "\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    loss            = EuclideanLoss(graph, \"loss\")\n",
    "\n",
    "    error = MSE(graph, \"mse\", config={\n",
    "        \"root\": True,\n",
    "        \"is_output\": True,\n",
    "        \"phase\": PHASE_TRAIN\n",
    "    })\n",
    "\n",
    "    # Connect\n",
    "    data.connect(conv_c1_1)\n",
    "    conv_c1_1.connect(conv_c1_2)\n",
    "    conv_c1_2.connect(concat_1)\n",
    "    conv_c1_2.connect(pool_c1)\n",
    "    pool_c1.connect(conv_c2_1)\n",
    "    conv_c2_1.connect(conv_c2_2)\n",
    "    conv_c2_2.connect(up_e2)\n",
    "    up_e2.connect(up_conv_e2)\n",
    "    up_conv_e2.connect(concat_1)\n",
    "    concat_1.connect(conv_e1_1)\n",
    "    conv_e1_1.connect(conv_e1_2)\n",
    "    conv_e1_2.connect(conv_e_f)\n",
    "    \n",
    "    conv_e_f.connect(loss)\n",
    "    conv_e_f.connect(error)\n",
    "    \n",
    "    label.connect(loss)\n",
    "    label.connect(error)\n",
    "    \n",
    "    \n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016-04-12 07:57:55] INFO: Pipeline - Starting computation\n",
      "[2016-04-12 07:57:55] INFO: Graph - Loading parameters from file '../data/unet_test_two_paths_only_iter_20000.zip'\n",
      "[2016-04-12 07:57:55] INFO: Graph - Setting up graph\n",
      "[2016-04-12 07:57:55] INFO: Node - data has shape (-1, 3, 228, 304)\n",
      "[2016-04-12 07:57:55] INFO: Node - label has shape (-1, 1, 228, 304)\n",
      "[2016-04-12 07:57:55] INFO: Node - conv_c1_1 has shape (-1, 64, 228, 304)\n",
      "[2016-04-12 07:57:55] INFO: Node - conv_c1_2 has shape (-1, 64, 228, 304)\n",
      "[2016-04-12 07:57:55] INFO: Node - pool_c0 has shape (-1, 64, 114, 152)\n",
      "[2016-04-12 07:57:55] INFO: Node - conv_c2_1 has shape (-1, 128, 114, 152)\n",
      "[2016-04-12 07:57:55] INFO: Node - conv_c2_2 has shape (-1, 128, 114, 152)\n",
      "[2016-04-12 07:57:55] INFO: Node - up_e2 has shape (-1, 128, 228, 304)\n",
      "[2016-04-12 07:57:55] INFO: Node - up_conv_e2 has shape (-1, 64, 228, 304)\n",
      "[2016-04-12 07:57:55] INFO: Node - concat_1 has shape (-1, 128, 228, 304)\n",
      "[2016-04-12 07:57:55] INFO: Node - conv_e1_1 has shape (-1, 64, 228, 304)\n",
      "[2016-04-12 07:57:55] INFO: Node - conv_e1_2 has shape (-1, 64, 228, 304)\n",
      "[2016-04-12 07:57:55] INFO: Node - conv_e_f has shape (-1, 1, 228, 304)\n",
      "[2016-04-12 07:57:55] INFO: Node - loss has shape (1,)\n",
      "[2016-04-12 07:57:55] INFO: Node - mse has shape (1,)\n",
      "[2016-04-12 07:57:56] INFO: Graph - Invoking Theano compiler\n",
      "[2016-04-12 07:58:06] INFO: Optimizer - Compilation finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ga29mix/anaconda/envs/deep/lib/python2.7/site-packages/ipykernel/__main__.py:65: DeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "/home/ga29mix/anaconda/envs/deep/lib/python2.7/site-packages/ipykernel/__main__.py:66: DeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    batch_size = 16\n",
    "    chunk_size = 10*batch_size\n",
    "    transfer_shape = ((chunk_size, 3, 228, 304), (chunk_size, 228, 304))\n",
    "\n",
    "    g = build_graph()\n",
    "\n",
    "    # Build the training pipeline\n",
    "    db_loader = H5DBLoader(\"db\", ((chunk_size, 3, 480, 640), (chunk_size, 1, 480, 640)), config={\n",
    "        \"db\": '/home/ga29mix/nashome/data/nyu_depth_v2_combined_50.hdf5',\n",
    "        # \"db\": '../data/nyu_depth_unet_large.hdf5',\n",
    "        \"key_data\": \"images\",\n",
    "        \"key_label\": \"depths\",\n",
    "        \"chunk_size\": chunk_size\n",
    "    })\n",
    "    transformer = Transformer(\"tr\", transfer_shape, config={\n",
    "        # Measured for the data-set\n",
    "        # \"offset\": 2.7321029\n",
    "        \"mean_file\": \"/home/ga29mix/nashome/data/nyu_depth_v2_combined_50.npy\"\n",
    "    })\n",
    "    optimizer = Optimizer(\"opt\", g, transfer_shape, config={\n",
    "        \"batch_size\":  batch_size,\n",
    "        \"chunk_size\": chunk_size,\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"momentum\": 0.9,\n",
    "        \"weight_decay\": 0.0005,\n",
    "        \"print_freq\": 50,\n",
    "        \"save_freq\": 10000,\n",
    "        \"weights\": \"../data/unet_test_two_paths_only_iter_20000.zip\",\n",
    "        \"save_prefix\": \"../data/unet_test_two_paths_only\"\n",
    "    })\n",
    "\n",
    "    p = Pipeline(config={\n",
    "        \"validation_frequency\": 50,\n",
    "        \"cycles\": 6200\n",
    "    })\n",
    "    p.add(db_loader)\n",
    "    p.add(transformer)\n",
    "    p.add(optimizer)\n",
    "    p.run()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = build_graph()\n",
    "g.load_weights(\"../data/alexnet_scale_1_iter_19000.zip\")\n",
    "g.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py, numpy as np\n",
    "\n",
    "f = h5py.File(\"/home/ga29mix/nashome/data/nyu_depth_v2_combined_50.hdf5\")\n",
    "\n",
    "b = int(f[\"images\"].shape[0] * 0.9)\n",
    "images = np.array(f[\"images\"][b:])\n",
    "depths = np.array(f[\"depths\"][b:])\n",
    "print images.shape\n",
    "mean = np.load(\"/home/ga29mix/nashome/data/nyu_depth_v2_combined_50.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from deepgraph.nn.core import Dropout\n",
    "w = 304\n",
    "h = 228\n",
    "plot = True\n",
    "idx = 100\n",
    "diffs = []\n",
    "Dropout.set_dp_off()\n",
    "for image in images[100:120]:\n",
    "    tmp = image.astype(np.float32)\n",
    "    tmp -= mean\n",
    "    cy = (tmp.shape[1] - h) // 2\n",
    "    cx = (tmp.shape[2] - w) // 2\n",
    "    crop = tmp[:,cy:cy+h, cx:cx+w]\n",
    "    res = g.infer([crop.reshape((1,3,228,304))])[\"reshape_0\"]\n",
    "    res = res.squeeze()\n",
    "    depth = depths[idx][cy:cy + h, cx:cx + w]\n",
    "    depth = depth[::4,::4]\n",
    "    if plot and idx % 5 == 0:\n",
    "        \n",
    "        plt.imshow(image.transpose((1,2,0)).astype(np.uint8))\n",
    "        plt.show()\n",
    "        plt.imshow(depth)\n",
    "        plt.show()\n",
    "        plt.imshow(res)\n",
    "        plt.show()\n",
    "        print \"RMSE: \" + str(np.sqrt(np.mean((res-depth)**2)))\n",
    "    diffs.append(res - depth)\n",
    "    \n",
    "    idx += 1\n",
    "    \n",
    "diffs = np.array(diffs)\n",
    "rmse = np.sqrt(np.mean(diffs ** 2))\n",
    "print \"Accumulated RMSE: \" + str(rmse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
