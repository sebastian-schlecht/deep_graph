{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from deepgraph.utils.logging import log\n",
    "from deepgraph.utils.common import batch_parallel, ConfigMixin, shuffle_in_unison_inplace, pickle_dump\n",
    "from deepgraph.utils.image import batch_pad_mirror\n",
    "from deepgraph.constants import *\n",
    "from deepgraph.conf import rng\n",
    "\n",
    "from deepgraph.pipeline import Processor, Packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from deepgraph.nn.init import *\n",
    "class Transformer(Processor):\n",
    "    \"\"\"\n",
    "    Apply online random augmentation.\n",
    "    \"\"\"\n",
    "    def __init__(self, name, shapes, config, buffer_size=10):\n",
    "        super(Transformer, self).__init__(name, shapes, config, buffer_size)\n",
    "        self.mean = None\n",
    "\n",
    "    def init(self):\n",
    "        if self.conf(\"mean_file\") is not None:\n",
    "            self.mean = np.load(self.conf(\"mean_file\"))\n",
    "        else:\n",
    "            log(\"Transformer - No mean file specified.\", LOG_LEVEL_WARNING)\n",
    "\n",
    "    def process(self):\n",
    "        packet = self.pull()\n",
    "        # Return if no data is there\n",
    "        if not packet:\n",
    "            return False\n",
    "        # Unpack\n",
    "        data, label = packet.data\n",
    "        # Do processing\n",
    "        log(\"Transformer - Processing data\", LOG_LEVEL_VERBOSE)\n",
    "        \n",
    "        h = 240\n",
    "        w = 320\n",
    "        \n",
    "        start = time.time()\n",
    "        # Mean\n",
    "        if packet.phase == PHASE_TRAIN or packet.phase == PHASE_VAL:\n",
    "            data = data.astype(np.float32)\n",
    "            if self.mean is not None:\n",
    "                std = self.conf(\"std\")\n",
    "                for idx in range(data.shape[0]):\n",
    "                    # Subtract mean\n",
    "                    data[idx] = data[idx] - self.mean.astype(np.float32)\n",
    "                    if std is not None:\n",
    "                        data[idx] =  data[idx] * std\n",
    "            if self.conf(\"offset\") is not None:\n",
    "                label -= self.conf(\"offset\")\n",
    "\n",
    "        if packet.phase == PHASE_TRAIN:\n",
    "             # Do elementwise operations\n",
    "            data_old = data\n",
    "            label_old = label\n",
    "            data = np.zeros((data_old.shape[0], data_old.shape[1], h, w), dtype=np.float32)\n",
    "            label = np.zeros((label_old.shape[0], h, w), dtype=np.float32)\n",
    "            for idx in range(data.shape[0]):\n",
    "                # Rotate\n",
    "                # We rotate before cropping to be able to get filled corners\n",
    "                # Maybe even adjust the border after rotating\n",
    "                deg = np.random.randint(-5,6)\n",
    "                # Operate on old data. Careful - data is already in float so we need to normalize and rescale afterwards\n",
    "                # data_old[idx] = 255. * rotate_transformer_rgb_uint8(data_old[idx] * 0.003921568627, deg).astype(np.float32)\n",
    "                # label_old[idx] = rotate_transformer_scalar_float32(label_old[idx], deg)\n",
    "                \n",
    "                # Take care of any empty areas, we crop on a smaller surface depending on the angle\n",
    "                # TODO Remove this once loss supports masking\n",
    "                shift = 0 #np.tan((deg/180.) * math.pi)\n",
    "                # Random crops\n",
    "                #cy = rng.randint(data_old.shape[2] - h - shift, size=1)\n",
    "                #cx = rng.randint(data_old.shape[3] - w - shift, size=1)\n",
    "\n",
    "                data[idx] = data_old[idx]\n",
    "                label[idx] = label_old[idx]\n",
    "\n",
    "                # Flip horizontally with probability 0.5\n",
    "                \"\"\"\n",
    "                p = rng.randint(2)\n",
    "                if p > 0:\n",
    "                    data[idx] = data[idx, :, :, ::-1]\n",
    "                    label[idx] = label[idx, :, ::-1]\n",
    "\n",
    "                # RGB we mult with a random value between 0.8 and 1.2\n",
    "                r = rng.randint(80,121) / 100.\n",
    "                g = rng.randint(80,121) / 100.\n",
    "                b = rng.randint(80,121) / 100.\n",
    "                data[idx, 0] = data[idx, 0] * r\n",
    "                data[idx, 1] = data[idx, 1] * g\n",
    "                data[idx, 2] = data[idx, 2] * b\n",
    "                \"\"\"\n",
    "            # Shuffle\n",
    "            # data, label = shuffle_in_unison_inplace(data, label)\n",
    "            \n",
    "        elif packet.phase == PHASE_VAL:\n",
    "            # Center crop\n",
    "            pass\n",
    "            #cy = (data.shape[2] - h) // 2\n",
    "            #cx = (data.shape[3] - w) // 2\n",
    "            #data = data[:, :, cy:cy+h, cx:cx+w]\n",
    "            #label = label[:, cy:cy+h, cx:cx+w]\n",
    "            \n",
    "        end = time.time()\n",
    "        log(\"Transformer - Processing took \" + str(end - start) + \" seconds.\", LOG_LEVEL_VERBOSE)\n",
    "        # Try to push into queue as long as thread should not terminate\n",
    "        self.push(Packet(identifier=packet.id, phase=packet.phase, num=2, data=(data, label)))\n",
    "        return True\n",
    "\n",
    "    def setup_defaults(self):\n",
    "        super(Transformer, self).setup_defaults()\n",
    "        self.conf_default(\"mean_file\", None)\n",
    "        self.conf_default(\"offset\", None)\n",
    "        self.conf_default(\"std\", 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano.tensor.nnet import relu\n",
    "\n",
    "from deepgraph.graph import *\n",
    "from deepgraph.nn.core import *\n",
    "from deepgraph.nn.conv import *\n",
    "from deepgraph.nn.loss import *\n",
    "\n",
    "from deepgraph.pipeline import Optimizer, H5DBLoader, Pipeline\n",
    "\n",
    "# Print to console for testing\n",
    "\n",
    "\n",
    "def build_u_graph():\n",
    "    graph = Graph(\"u_depth\")\n",
    "\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    \"\"\"\n",
    "    data = Data(graph, \"data\", T.ftensor4, shape=(-1, 3, 240, 320))\n",
    "    label = Data(graph, \"label\", T.ftensor3, shape=(-1, 1, 240, 320), config={\n",
    "        \"phase\": PHASE_TRAIN\n",
    "    })\n",
    "    \"\"\"\n",
    "    Contractive part\n",
    "    \"\"\"\n",
    "    conv_1 = Conv2D(\n",
    "        graph,\n",
    "        \"conv_1\",\n",
    "        config={\n",
    "            \"channels\": 64,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    conv_2 = Conv2D(\n",
    "        graph,\n",
    "        \"conv_2\",\n",
    "        config={\n",
    "            \"channels\": 64,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    pool_2 = Pool(graph, \"pool_2\", config={\n",
    "        \"kernel\": (2, 2)\n",
    "    })\n",
    "    conv_3 = Conv2D(\n",
    "        graph,\n",
    "        \"conv_3\",\n",
    "        config={\n",
    "            \"channels\": 128,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    conv_4 = Conv2D(\n",
    "        graph,\n",
    "        \"conv_4\",\n",
    "        config={\n",
    "            \"channels\": 128,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    pool_4 = Pool(graph, \"pool_4\", config={\n",
    "        \"kernel\": (2, 2)\n",
    "    })\n",
    "    conv_5 = Conv2D(\n",
    "        graph,\n",
    "        \"conv_5\",\n",
    "        config={\n",
    "            \"channels\": 256,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    conv_6 = Conv2D(\n",
    "        graph,\n",
    "        \"conv_6\",\n",
    "        config={\n",
    "            \"channels\": 256,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    pool_6 = Pool(graph, \"pool_6\", config={\n",
    "        \"kernel\": (2, 2),\n",
    "    })\n",
    "\n",
    "    conv_7 = Conv2D(\n",
    "        graph,\n",
    "        \"conv_7\",\n",
    "        config={\n",
    "            \"channels\": 512,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    conv_8 = Conv2D(\n",
    "        graph,\n",
    "        \"conv_8\",\n",
    "        config={\n",
    "            \"channels\": 512,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    pool_8 = Pool(graph, \"pool_8\", config={\n",
    "        \"kernel\": (2, 2)\n",
    "    })\n",
    "\n",
    "    \"\"\"\n",
    "    Prediction core\n",
    "    \"\"\"\n",
    "    conv_9 = Conv2D(\n",
    "        graph,\n",
    "        \"conv_9\",\n",
    "        config={\n",
    "            \"channels\": 128,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    fl_10 = Flatten(graph, \"pc_10\", config={\n",
    "        \"dims\" : 2    \n",
    "    })\n",
    "    fc_10a = Dense(graph, \"fc_10a\", config={\n",
    "            \"out\": 4096,\n",
    "            \"activation\": None,\n",
    "            \"weight_filler\": xavier(),\n",
    "            \"bias_filler\": constant(1)\n",
    "    })\n",
    "    dp_10a = Dropout(graph, \"dp_10a\", config={\n",
    "    })\n",
    "    fc_10 = Dense(graph, \"fc_10\", config={\n",
    "            \"out\": 19200,\n",
    "            \"activation\": None,\n",
    "            \"weight_filler\": xavier(),\n",
    "            \"bias_filler\": constant(1)\n",
    "    })\n",
    "    dp_10 = Dropout(graph, \"dp_10\", config={\n",
    "    })\n",
    "    rs_10 = Reshape(graph, \"rs_10\", config={\n",
    "            \"shape\": (-1, 64, 15, 20)\n",
    "    })\n",
    "    conv_10 = Conv2D(\n",
    "            graph,\n",
    "            \"conv_10\",\n",
    "            config={\n",
    "                \"channels\": 64,\n",
    "                \"kernel\": (3, 3),\n",
    "                \"border_mode\": 1,\n",
    "                \"activation\": relu,\n",
    "                \"weight_filler\": xavier(gain=\"relu\"),\n",
    "                \"bias_filler\": constant(0)\n",
    "            }\n",
    "    )\n",
    "    \"\"\"\n",
    "    Expansive path\n",
    "    \"\"\"\n",
    "    up_11 = Upsample(graph, \"up_11\", config={\n",
    "        \"kernel\": (2, 2)\n",
    "    })\n",
    "    upconv_11 = Conv2D(\n",
    "        graph,\n",
    "        \"upconv_11\",\n",
    "        config={\n",
    "            \"channels\": 512,\n",
    "            \"kernel\": (3,3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": None,\n",
    "            \"weight_filler\": xavier(),\n",
    "            \"bias_filler\": constant(0)\n",
    "    })\n",
    "    \n",
    "    conv_12 = Conv2D(\n",
    "        graph,\n",
    "        \"conv_12\",\n",
    "        config={\n",
    "            \"channels\": 512,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    conv_13 = Conv2D(\n",
    "        graph,\n",
    "        \"conv_13\",\n",
    "        config={\n",
    "            \"channels\": 512,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    up_14 = Upsample(graph, \"up_14\", config={\n",
    "        \"kernel\": (2, 2)\n",
    "    })\n",
    "    upconv_14 = Conv2D(\n",
    "        graph,\n",
    "        \"upconv_14\",\n",
    "        config={\n",
    "            \"channels\": 256,\n",
    "            \"kernel\": (3,3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": None,\n",
    "            \"weight_filler\": xavier(),\n",
    "            \"bias_filler\": constant(0)\n",
    "    })\n",
    "    conv_15 = Conv2D(\n",
    "        graph,\n",
    "        \"conv_15\",\n",
    "        config={\n",
    "            \"channels\": 256,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"weight_filler\": xavier(),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    conv_16 = Conv2D(\n",
    "        graph,\n",
    "        \"conv_16\",\n",
    "        config={\n",
    "            \"channels\": 256,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    up_17 = Upsample(graph, \"up_17\", config={\n",
    "        \"kernel\": (2, 2)\n",
    "    })\n",
    "    upconv_17 = Conv2D(\n",
    "        graph,\n",
    "        \"upconv_17\",\n",
    "        config={\n",
    "            \"channels\": 128,\n",
    "            \"kernel\": (3,3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": None,\n",
    "            \"weight_filler\": xavier(),\n",
    "            \"bias_filler\": constant(0)\n",
    "    })\n",
    "    conv_18 = Conv2D(\n",
    "        graph,\n",
    "        \"conv_18\",\n",
    "        config={\n",
    "            \"channels\": 128,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    conv_19 = Conv2D(\n",
    "        graph,\n",
    "        \"conv_19\",\n",
    "        config={\n",
    "            \"channels\": 128,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    up_20 = Upsample(graph, \"up_20\", config={\n",
    "        \"mode\": \"constant\",\n",
    "        \"kernel\": (2, 2)\n",
    "    })\n",
    "    upconv_20 = Conv2D(\n",
    "        graph,\n",
    "        \"upconv_20\",\n",
    "        config={\n",
    "            \"channels\": 64,\n",
    "            \"kernel\": (3,3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": None,\n",
    "            \"weight_filler\": xavier(),\n",
    "            \"bias_filler\": constant(0)\n",
    "    })\n",
    "   \n",
    "    conv_21 = Conv2D(\n",
    "        graph,\n",
    "        \"conv_21\",\n",
    "        config={\n",
    "            \"channels\": 64,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    conv_22 = Conv2D(\n",
    "        graph,\n",
    "        \"conv_22\",\n",
    "        config={\n",
    "            \"channels\": 64,\n",
    "            \"kernel\": (3, 3),\n",
    "            \"border_mode\": 1,\n",
    "            \"activation\": relu,\n",
    "            \"weight_filler\": xavier(gain=\"relu\"),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "    conv_23 = Conv2D(\n",
    "        graph,\n",
    "        \"conv_23\",\n",
    "        config={\n",
    "            \"channels\": 1,\n",
    "            \"kernel\": (1, 1),\n",
    "            \"weight_filler\": xavier(),\n",
    "            \"bias_filler\": constant(0)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    \"\"\"\n",
    "    Feed forward nodes\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    concat_20 = Concatenate(graph, \"concat_20\", config={\n",
    "        \"axis\": 1\n",
    "    })\n",
    "    \n",
    "    concat_17 = Concatenate(graph, \"concat_17\", config={\n",
    "        \"axis\": 1\n",
    "    })\n",
    "\n",
    "    concat_14 = Concatenate(graph, \"concat_14\", config={\n",
    "        \"axis\": 1\n",
    "    })\n",
    "\n",
    "    concat_11 = Concatenate(graph, \"concat_11\", config={\n",
    "        \"axis\": 1\n",
    "    })\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Losses / Error\n",
    "    \"\"\"\n",
    "    loss = EuclideanLoss(graph, \"loss\")\n",
    "\n",
    "    error = MSE(graph, \"mse\", config={\n",
    "        \"root\": True,\n",
    "        \"is_output\": True,\n",
    "        \"phase\": PHASE_TRAIN\n",
    "    })\n",
    "    \n",
    "    \"\"\"\n",
    "    Make connections\n",
    "    \"\"\"\n",
    "    data.connect(conv_1)\n",
    "    conv_1.connect(conv_2)\n",
    "    conv_2.connect(concat_20)\n",
    "    conv_2.connect(pool_2)\n",
    "\n",
    "    pool_2.connect(conv_3)\n",
    "    conv_3.connect(conv_4)\n",
    "    conv_4.connect(concat_17)\n",
    "    conv_4.connect(pool_4)\n",
    "    pool_4.connect(conv_5)\n",
    "    conv_5.connect(conv_6)\n",
    "    conv_6.connect(concat_14)\n",
    "    conv_6.connect(pool_6)\n",
    "    pool_6.connect(conv_7)\n",
    "    conv_7.connect(conv_8)\n",
    "    conv_8.connect(concat_11)\n",
    "    conv_8.connect(pool_8)\n",
    "    pool_8.connect(conv_9)\n",
    "    conv_9.connect(fl_10)\n",
    "    fl_10.connect(fc_10a)\n",
    "    fc_10a.connect(dp_10a)\n",
    "    dp_10a.connect(fc_10)\n",
    "    fc_10.connect(dp_10)\n",
    "    dp_10.connect(rs_10)\n",
    "    rs_10.connect(conv_10)\n",
    "    conv_10.connect(up_11)\n",
    "    up_11.connect(upconv_11)\n",
    "    upconv_11.connect(concat_11)\n",
    "    concat_11.connect(conv_12)\n",
    "    conv_12.connect(conv_13)\n",
    "    conv_13.connect(up_14)\n",
    "    up_14.connect(upconv_14)\n",
    "    upconv_14.connect(concat_14)\n",
    "    concat_14.connect(conv_15)\n",
    "    conv_15.connect(conv_16)\n",
    "    conv_16.connect(up_17)\n",
    "    up_17.connect(upconv_17)\n",
    "    upconv_17.connect(concat_17)\n",
    "    concat_17.connect(conv_18)\n",
    "    conv_18.connect(conv_19)\n",
    "    conv_19.connect(up_20)\n",
    "    up_20.connect(upconv_20)\n",
    "    upconv_20.connect(concat_20)\n",
    "    concat_20.connect(conv_21)\n",
    "    conv_21.connect(conv_22)\n",
    "    conv_22.connect(conv_23)\n",
    "\n",
    "    conv_23.connect(loss)\n",
    "    label.connect(loss)\n",
    "\n",
    "    conv_23.connect(error)\n",
    "    label.connect(error)\n",
    "    \n",
    "\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    batch_size = 8\n",
    "    chunk_size = 10*batch_size\n",
    "    transfer_shape = ((chunk_size, 3, 240, 320), (chunk_size, 240, 320))\n",
    "\n",
    "    g = build_u_graph()\n",
    "\n",
    "    # Build the training pipeline\n",
    "    db_loader = H5DBLoader(\"db\", ((chunk_size, 3, 480, 640), (chunk_size, 1, 480, 640)), config={\n",
    "        \"db\": '/home/ga29mix/nashome/data/nyu_depth_v2_combined_50.hdf5',\n",
    "        # \"db\": '../data/nyu_depth_unet_large.hdf5',\n",
    "        \"key_data\": \"images\",\n",
    "        \"key_label\": \"depths\",\n",
    "        \"chunk_size\": chunk_size\n",
    "    })\n",
    "    transformer = Transformer(\"tr\", transfer_shape, config={\n",
    "        # Measured for the data-set\n",
    "        # \"offset\": 2.7321029\n",
    "        \"mean_file\" : \"/home/ga29mix/nashome/data/nyu_depth_v2_combined_50.npy\",\n",
    "        \"std\": 1.0 / 76.18328376\n",
    "    })\n",
    "    optimizer = Optimizer(\"opt\", g, transfer_shape, config={\n",
    "        \"batch_size\":  batch_size,\n",
    "        \"chunk_size\": chunk_size,\n",
    "        \"learning_rate\": 0.001,\n",
    "        # \"learning_rate\": 0.000001 converges ( a bit)\n",
    "        \"momentum\": 0.9,\n",
    "        \"weight_decay\": 0.0005,\n",
    "        \"print_freq\": 200,\n",
    "        \"save_freq\": 10000,\n",
    "        # \"weights\": \"../data/vnet_init_2_iter_4500.zip\",\n",
    "        \"save_prefix\": \"../data/vnet\"\n",
    "    })\n",
    "\n",
    "    p = Pipeline(config={\n",
    "        \"validation_frequency\": 15,\n",
    "        \"cycles\": 3000\n",
    "    })\n",
    "    p.add(db_loader)\n",
    "    p.add(transformer)\n",
    "    p.add(optimizer)\n",
    "    p.run()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "l = np.array([e[\"loss\"] for e in optimizer.losses])\n",
    "print len(l)\n",
    "plt.plot(l)\n",
    "\n",
    "# print g.last_updates[2].get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
